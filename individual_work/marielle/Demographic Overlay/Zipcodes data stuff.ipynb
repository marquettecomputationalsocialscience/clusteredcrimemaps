{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = gpd.read_file('./tl_2010_55079_tract10/tl_2010_55079_tract10.shp')\n",
    "data = data.sort_values('TRACTCE10')\n",
    "data['White'] = 0\n",
    "data['Black or African American'] = 0 \n",
    "data['American Indian and Ala Native'] = 0\n",
    "data['Asian'] = 0\n",
    "data['Native Hawaiian/other Pac Isl'] = 0\n",
    "data['Multiple Race'] = 0\n",
    "data['Other Race'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('DEC_10_SF1_QTP3_with_ann.csv')\n",
    "census_drop_list = ['HD01_S01','HD01_S02','HD02_S01','HD02_S02','HD02_S03',\n",
    "                   'HD02_S04','HD02_S05','HD02_S06','HD02_S07','HD02_S08',\n",
    "                   'HD02_S09','HD02_S10','HD02_S18','HD02_S23','HD02_S24',\n",
    "                   'HD02_S25','HD02_S26','HD02_S27','HD02_S28','HD01_S06',\n",
    "                   'HD01_S07','HD01_S08','HD01_S09','HD01_S25','HD01_S26',\n",
    "                   'HD01_S27','HD01_S28','HD02_S29','HD02_S30','HD02_S31',\n",
    "                   'HD01_S31','HD01_S32','HD02_S32','HD01_S33','HD02_S33',\n",
    "                   'HD01_S34','HD02_S34','HD01_S35','HD02_S35','HD01_S29',\n",
    "                   'HD01_S30','HD02_S36','HD01_S37','HD02_S37','HD02_S38',\n",
    "                   'HD01_S39','HD02_S39','HD01_S40','HD02_S40','HD01_S41',\n",
    "                   'HD02_S41','HD01_S42','HD02_S42']\n",
    "\n",
    "df =df.drop(census_drop_list,axis=1)\n",
    "\n",
    "df.columns = df.loc[0]\n",
    "df = df.drop(0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in df.Id2:\n",
    "    series = df[df['Id2'] == item].drop('Id',axis =1).drop(\n",
    "    'Id2', axis=1).drop('Geography', axis=1).drop(\n",
    "    'Number; RACE AND HISPANIC OR LATINO - Total population',axis=1).drop(\n",
    "    'Number; RACE AND HISPANIC OR LATINO - Total population - One race - Hispanic or Latino',axis=1)\n",
    "    \n",
    "    data.loc[data.GEOID10 == item,['White','Black or African American',\n",
    "                                   'American Indian and Ala Native',\n",
    "                                   'Asian', 'Native Hawaiian/other Pac Isl',\n",
    "                                   'Multiple Race', 'Other Race']] = series.sum(axis=0).astype(np.int).tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['980000', '990000']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_list = []\n",
    "for index in data.index:\n",
    "    if np.all(data.loc[index,['White','Black or African American','Asian',\n",
    "            'Native Hawaiian/other Pac Isl','Multiple Race','Other Race']] == 0):\n",
    "        missing_list.append(data.loc[index,'TRACTCE10'])\n",
    "  #      data = data.drop(index)\n",
    "  #  else:\n",
    "        #data = data.drop(index)\n",
    "        \n",
    "missing_list.sort()\n",
    "missing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delete_list = ['050101','050102','040100','060102','060200','070200',\n",
    "              '070100','080100','035200','030100','035100','070300',\n",
    "              '080400','990000','185100','180100','180200','180500',\n",
    "              '170200','170300','170100','170700','170600','170300',\n",
    "              '160100','150100','120501','140202','150304','060101',\n",
    "              '080200','185200','180300','180400','120502','120400',\n",
    "              '120202','140201','140100','150301','130200','130100',\n",
    "              '120101','120102','101000','101100','100900','090100',\n",
    "              '090200','091000','090900','091100','091200','091400',\n",
    "              '091300','090700','185300','090300','090600','100800',\n",
    "              '110100','100100','100200','101600','100300','100400',\n",
    "              '101500','101700','101800','101200','101300','101400',\n",
    "              '100500','100600','100700','120201','120203','150303',\n",
    "              '090800','120300','080300']\n",
    "data = data.drop(data.loc[data.TRACTCE10.isin(delete_list)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('../KMeans/zipcodes.js')\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "data.to_file('../KMeans/census.geoJSON', driver='GeoJSON')\n",
    "data.to_file('../KMeans/zipcodes.js', driver='GeoJSON')\n",
    "\n",
    "with open('../KMeans/zipcodes.js', 'r') as original: data = original.read()\n",
    "with open('../KMeans/zipcodes.js', 'w') as modified: modified.write(\"var zipcodes =\" \n",
    "                                                        + data +';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
